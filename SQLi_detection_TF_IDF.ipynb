{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SQL Injection Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from texttable import Texttable\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.sparse import hstack\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import GradientBoostingClassifier, AdaBoostClassifier, RandomForestClassifier, StackingClassifier\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score, accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('./Dataset/dataset.csv')\n",
    "data.drop_duplicates(inplace=True)\n",
    "data = data.dropna(subset=['Label', 'Query'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funzione per estrarre le caratteristiche da una query SQL\n",
    "def extract_features(query):\n",
    "    features = {}\n",
    "    features['no_sngle_quts'] = query.count(\"'\")  # Number of single quotes\n",
    "    features['no_dble_quts'] = query.count('\"')  # Number of double quotes\n",
    "    features['no_punctn'] = sum([1 for char in query if char in '!@#$%^&*()-_=+[{]};:\\'\",<.>/?\\\\|`~'])  # Number of punctuations\n",
    "    features['no_sgle_cmnt'] = query.count('--')  # Number of single line comments\n",
    "    features['no_mlt_cmnt'] = query.count('/*') + query.count('*/')  # Number of multi-line comments\n",
    "    features['no_whte_spce'] = query.count(' ')  # Number of white spaces\n",
    "    features['no_nrml_kywrds'] = len(re.findall(r'\\b(select|from|where|insert|delete|update|join|union)\\b', query, re.IGNORECASE))  # Normal keywords\n",
    "    features['no_hmfl_kywrds'] = len(re.findall(r'\\b(exec|shutdown|cmdshell|ascii|hex|char|concat)\\b', query, re.IGNORECASE))  # Harmful keywords\n",
    "    features['no_prctge'] = query.count('%')  # Number of percentage symbols\n",
    "    features['no_log_oprtr'] = len(re.findall(r'\\b(and|or|not)\\b', query, re.IGNORECASE))  # Logical operators\n",
    "    features['no_oprtr'] = sum([1 for char in query if char in '=<>'])  # Number of operators\n",
    "    features['no_null_valus'] = query.lower().count('null')  # Number of null values\n",
    "    features['no_hexdcml_valus'] = len(re.findall(r'0x[0-9a-fA-F]+', query))  # Number of hexadecimal values\n",
    "    features['no_db_info_cmnds'] = len(re.findall(r'\\b(database|information_schema|version)\\b', query, re.IGNORECASE))  # Database information commands\n",
    "    features['no_roles'] = len(re.findall(r'\\b(admin|user|guest)\\b', query, re.IGNORECASE))  # Roles\n",
    "    features['no_ntwr_cmnds'] = len(re.findall(r'\\b(load_file|benchmark|sleep)\\b', query, re.IGNORECASE))  # Network commands\n",
    "    features['no_lanage_cmnds'] = len(re.findall(r'\\b(exec|declare|open|fetch|close|deallocate|prepare|execute)\\b', query, re.IGNORECASE))  # Language commands\n",
    "    features['no_alphabet'] = len(re.findall(r'[a-zA-Z]', query))  # Number of alphabets\n",
    "    features['no_digits'] = len(re.findall(r'\\d', query))  # Number of digits\n",
    "    features['no_spl_chrtr'] = len(re.findall(r'[^a-zA-Z0-9\\s]', query))  # Number of special characters\n",
    "    return features\n",
    "\n",
    "# Evaluation function\n",
    "def evaluate_model(y_true, y_pred):\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred)\n",
    "    recall = recall_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "    conf_matrix = confusion_matrix(y_true, y_pred)\n",
    "    roc_auc = roc_auc_score(y_true, y_pred)\n",
    "    return {\"accuracy\": accuracy, \"precision\": precision, \"recall\": recall, \"f1\": f1, \"conf_matrix\": conf_matrix, \"roc_auc\": roc_auc}\n",
    "\n",
    "# Function to plot confusion matrix\n",
    "def plot_confusion_matrix(y_true, y_pred, title, filename):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "    disp.plot(cmap=plt.cm.Blues)\n",
    "    plt.title(title, fontsize=16)\n",
    "    plt.xlabel('Predicted Label', fontsize=14)\n",
    "    plt.ylabel('True Label', fontsize=14)\n",
    "    \n",
    "    # Increase font size of the numbers in the confusion matrix\n",
    "    for labels in disp.text_.ravel():\n",
    "        labels.set_fontsize(14)\n",
    "    \n",
    "    plt.savefig(filename, format='png', dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "# Function to plot ROC-AUC Curve\n",
    "def plot_roc_auc_curve(y_true, y_pred_prob, model_name, filename):\n",
    "    fpr, tpr, _ = roc_curve(y_true, y_pred_prob)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc:.2f})')\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title(f'ROC-AUC Curve: {model_name}')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.savefig(filename, format='png', dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "def plot_classification_report(models_stats, filename_prefix):\n",
    "    metrics = ['roc_auc', 'precision', 'recall', 'f1']\n",
    "    models = list(models_stats.keys())\n",
    "    \n",
    "    # Prepare the data\n",
    "    report_data = []\n",
    "    for model, stats in models_stats.items():\n",
    "        report_data.append([stats['roc_auc'], stats['precision'], stats['recall'], stats['f1']])\n",
    "    \n",
    "    # Convert to DataFrame for easier plotting\n",
    "    report_df = pd.DataFrame(report_data, columns=metrics, index=models)\n",
    "\n",
    "    colors = ['#007bff', '#28a745', '#dc3545', '#ffc107']\n",
    "\n",
    "    # Plot all models in one go\n",
    "    ax = report_df.plot(kind='bar', figsize=(14, 8), width=0.7, color=colors, legend=False)  # Adjusted figure size\n",
    "    plt.title(\"Classification Report\", fontsize=16)\n",
    "    plt.xticks(rotation=45, ha='right')  # Rotate labels for better readability\n",
    "    plt.ylabel(\"Score (%)\", fontsize=14)\n",
    "    plt.xticks(fontsize=14)  # Increase font size for x-axis labels\n",
    "    plt.yticks(fontsize=14)  # Increase font size for y-axis labels\n",
    "    \n",
    "    # Set y-axis range for better differentiation\n",
    "    ax.set_ylim(0.8, 1.05)  # Adjust this range as per your needs\n",
    "    \n",
    "    # Annotate the bars with the actual values\n",
    "    for p in ax.patches:\n",
    "        ax.annotate(f'{p.get_height():.4f}', \n",
    "                    (p.get_x() + p.get_width() / 2., p.get_height()), \n",
    "                    ha='center', va='baseline', \n",
    "                    xytext=(0, -100), \n",
    "                    textcoords='offset points', fontsize=13, rotation=90)\n",
    "    \n",
    "    # Move legend to bottom left corner\n",
    "    plt.legend(loc='lower left')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"{filename_prefix}_all_models.png\", format='png', dpi=300)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Estrazione le caratteristiche dalle query\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m data_features \u001b[38;5;241m=\u001b[39m \u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mQuery\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mextract_features\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m data_features_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(data_features\u001b[38;5;241m.\u001b[39mtolist())\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Combina le caratteristiche estratte con le etichette\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\hp\\OneDrive - uniroma1.it\\Desktop\\Uni\\3Â°Anno uni\\Sicurezza\\SQLi detenction\\Security\\.venv\\lib\\site-packages\\pandas\\core\\series.py:4917\u001b[0m, in \u001b[0;36mSeries.apply\u001b[1;34m(self, func, convert_dtype, args, by_row, **kwargs)\u001b[0m\n\u001b[0;32m   4789\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(\n\u001b[0;32m   4790\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   4791\u001b[0m     func: AggFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4796\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   4797\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[0;32m   4798\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   4799\u001b[0m \u001b[38;5;124;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[0;32m   4800\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4915\u001b[0m \u001b[38;5;124;03m    dtype: float64\u001b[39;00m\n\u001b[0;32m   4916\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 4917\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSeriesApply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   4918\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4919\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4920\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconvert_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4921\u001b[0m \u001b[43m        \u001b[49m\u001b[43mby_row\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mby_row\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4922\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4923\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4924\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\hp\\OneDrive - uniroma1.it\\Desktop\\Uni\\3Â°Anno uni\\Sicurezza\\SQLi detenction\\Security\\.venv\\lib\\site-packages\\pandas\\core\\apply.py:1427\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1424\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_compat()\n\u001b[0;32m   1426\u001b[0m \u001b[38;5;66;03m# self.func is Callable\u001b[39;00m\n\u001b[1;32m-> 1427\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\hp\\OneDrive - uniroma1.it\\Desktop\\Uni\\3Â°Anno uni\\Sicurezza\\SQLi detenction\\Security\\.venv\\lib\\site-packages\\pandas\\core\\apply.py:1507\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1501\u001b[0m \u001b[38;5;66;03m# row-wise access\u001b[39;00m\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# apply doesn't have a `na_action` keyword and for backward compat reasons\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m \u001b[38;5;66;03m# we need to give `na_action=\"ignore\"` for categorical data.\u001b[39;00m\n\u001b[0;32m   1504\u001b[0m \u001b[38;5;66;03m# TODO: remove the `na_action=\"ignore\"` when that default has been changed in\u001b[39;00m\n\u001b[0;32m   1505\u001b[0m \u001b[38;5;66;03m#  Categorical (GH51645).\u001b[39;00m\n\u001b[0;32m   1506\u001b[0m action \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj\u001b[38;5;241m.\u001b[39mdtype, CategoricalDtype) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1507\u001b[0m mapped \u001b[38;5;241m=\u001b[39m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_map_values\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1508\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmapper\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcurried\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\n\u001b[0;32m   1509\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1511\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[38;5;241m0\u001b[39m], ABCSeries):\n\u001b[0;32m   1512\u001b[0m     \u001b[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[0;32m   1513\u001b[0m     \u001b[38;5;66;03m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[0;32m   1514\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_constructor_expanddim(\u001b[38;5;28mlist\u001b[39m(mapped), index\u001b[38;5;241m=\u001b[39mobj\u001b[38;5;241m.\u001b[39mindex)\n",
      "File \u001b[1;32mc:\\Users\\hp\\OneDrive - uniroma1.it\\Desktop\\Uni\\3Â°Anno uni\\Sicurezza\\SQLi detenction\\Security\\.venv\\lib\\site-packages\\pandas\\core\\base.py:921\u001b[0m, in \u001b[0;36mIndexOpsMixin._map_values\u001b[1;34m(self, mapper, na_action, convert)\u001b[0m\n\u001b[0;32m    918\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arr, ExtensionArray):\n\u001b[0;32m    919\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mmap(mapper, na_action\u001b[38;5;241m=\u001b[39mna_action)\n\u001b[1;32m--> 921\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43malgorithms\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_action\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\hp\\OneDrive - uniroma1.it\\Desktop\\Uni\\3Â°Anno uni\\Sicurezza\\SQLi detenction\\Security\\.venv\\lib\\site-packages\\pandas\\core\\algorithms.py:1743\u001b[0m, in \u001b[0;36mmap_array\u001b[1;34m(arr, mapper, na_action, convert)\u001b[0m\n\u001b[0;32m   1741\u001b[0m values \u001b[38;5;241m=\u001b[39m arr\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m na_action \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1743\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_infer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1745\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mmap_infer_mask(\n\u001b[0;32m   1746\u001b[0m         values, mapper, mask\u001b[38;5;241m=\u001b[39misna(values)\u001b[38;5;241m.\u001b[39mview(np\u001b[38;5;241m.\u001b[39muint8), convert\u001b[38;5;241m=\u001b[39mconvert\n\u001b[0;32m   1747\u001b[0m     )\n",
      "File \u001b[1;32mlib.pyx:2972\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[1;34m()\u001b[0m\n",
      "Cell \u001b[1;32mIn[6], line 17\u001b[0m, in \u001b[0;36mextract_features\u001b[1;34m(query)\u001b[0m\n\u001b[0;32m     15\u001b[0m features[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mno_null_valus\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m query\u001b[38;5;241m.\u001b[39mlower()\u001b[38;5;241m.\u001b[39mcount(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnull\u001b[39m\u001b[38;5;124m'\u001b[39m)  \u001b[38;5;66;03m# Number of null values\u001b[39;00m\n\u001b[0;32m     16\u001b[0m features[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mno_hexdcml_valus\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(re\u001b[38;5;241m.\u001b[39mfindall(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m0x[0-9a-fA-F]+\u001b[39m\u001b[38;5;124m'\u001b[39m, query))  \u001b[38;5;66;03m# Number of hexadecimal values\u001b[39;00m\n\u001b[1;32m---> 17\u001b[0m features[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mno_db_info_cmnds\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[43mre\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfindall\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mb(database|information_schema|version)\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mre\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mIGNORECASE\u001b[49m\u001b[43m)\u001b[49m)  \u001b[38;5;66;03m# Database information commands\u001b[39;00m\n\u001b[0;32m     18\u001b[0m features[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mno_roles\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(re\u001b[38;5;241m.\u001b[39mfindall(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mb(admin|user|guest)\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m, query, re\u001b[38;5;241m.\u001b[39mIGNORECASE))  \u001b[38;5;66;03m# Roles\u001b[39;00m\n\u001b[0;32m     19\u001b[0m features[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mno_ntwr_cmnds\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(re\u001b[38;5;241m.\u001b[39mfindall(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mb(load_file|benchmark|sleep)\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m, query, re\u001b[38;5;241m.\u001b[39mIGNORECASE))  \u001b[38;5;66;03m# Network commands\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Estrazione le caratteristiche dalle query\n",
    "data_features = data['Query'].apply(extract_features)\n",
    "data_features_df = pd.DataFrame(data_features.tolist())\n",
    "\n",
    "# Combina le caratteristiche estratte con le etichette\n",
    "df = pd.concat([data_features_df, data['Label']], axis=1)\n",
    "\n",
    "# Separazione delle caratteristiche (X) e le etichette (y)\n",
    "X_numerical = df.drop(columns=['Label'])\n",
    "y = df['Label']\n",
    "\n",
    "# Salva la colonna 'Query' per la successiva creazione delle BoW\n",
    "X_text = data['Query']\n",
    "\n",
    "# Divide i dati in set di addestramento e test mantenendo la colonna 'Query'\n",
    "X_train_numerical, X_test_numerical, X_train_text, X_test_text, y_train, y_test = train_test_split(\n",
    "    X_numerical, X_text, y, test_size=0.4)\n",
    "\n",
    "# Trasforma le caratteristiche testuali in TF-IDF\n",
    "vectorizer = TfidfVectorizer(ngram_range=(1, 2), max_features=1000)\n",
    "X_train_query = vectorizer.fit_transform(X_train_text)\n",
    "X_test_query = vectorizer.transform(X_test_text)\n",
    "\n",
    "# Combina le caratteristiche numeriche e testuali\n",
    "X_train = hstack((X_train_numerical.values, X_train_query)).tocsr()\n",
    "X_test = hstack((X_test_numerical.values, X_test_query)).tocsr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate of models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosting Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbm = GradientBoostingClassifier()\n",
    "gbm.fit(X_train, y_train)\n",
    "y_pred_gbm = gbm.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ada = AdaBoostClassifier()\n",
    "ada.fit(X_train, y_train)\n",
    "y_pred_ada = ada.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb = XGBClassifier(use_label_encoder=False, eval_metric='logloss')\n",
    "xgb.fit(X_train, y_train)\n",
    "y_pred_xgb = xgb.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm = LGBMClassifier()\n",
    "lgbm.fit(X_train, y_train)\n",
    "y_pred_lgbm = lgbm.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg = LogisticRegression(max_iter=100000)\n",
    "log_reg.fit(X_train, y_train)\n",
    "y_pred_log_reg = log_reg.fit(X_train, y_train).predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier()\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred_rf = rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier()\n",
    "knn.fit(X_train, y_train)\n",
    "y_pred_knn = knn.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = DecisionTreeClassifier()\n",
    "dt.fit(X_train, y_train)\n",
    "y_pred_dt = dt.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stacking Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators = [\n",
    "    ('gbm', gbm),\n",
    "    ('ada', ada),\n",
    "    ('xgb', xgb),\n",
    "    ('lgbm', lgbm),\n",
    "    ('rf', rf),\n",
    "    ('log_reg', log_reg),\n",
    "    ('knn', knn),\n",
    "    ('dt', dt)\n",
    "]\n",
    "\n",
    "stacking = StackingClassifier(estimators=estimators, final_estimator=LogisticRegression())\n",
    "stacking.fit(X_train.astype(np.float32), y_train.astype(np.float32))\n",
    "y_pred_stacking = stacking.predict(X_test.astype(np.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graphs print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stampa delle confusion matrix\n",
    "plot_confusion_matrix(y_test, y_pred_gbm, \"Gradient Boosting Machine Confusion Matrix\", \"./images_Bow/confusion_matrix/gbm_confusion_matrix.png\")\n",
    "plot_confusion_matrix(y_test, y_pred_ada, \"AdaBoost Confusion Matrix\", \"./images_Bow/confusion_matrix/ada_confusion_matrix.png\")\n",
    "plot_confusion_matrix(y_test, y_pred_xgb, \"XGBoost Confusion Matrix\", \"./images_Bow/confusion_matrix/xgb_confusion_matrix.png\")\n",
    "plot_confusion_matrix(y_test, y_pred_lgbm, \"LightGBM Confusion Matrix\", \"./images_Bow/confusion_matrix/lgbm_confusion_matrix.png\")\n",
    "plot_confusion_matrix(y_test, y_pred_log_reg, \"Logistic Regression Confusion Matrix\", \"./images_Bow/confusion_matrix/logreg_confusion_matrix.png\")\n",
    "plot_confusion_matrix(y_test, y_pred_rf, \"Random Forest Confusion Matrix\", \"./images_Bow/confusion_matrix/rf_confusion_matrix.png\")\n",
    "plot_confusion_matrix(y_test, y_pred_knn, \"K-Nearest Neighbors Confusion Matrix\", \"./images_Bow/confusion_matrix/knn_confusion_matrix.png\")\n",
    "plot_confusion_matrix(y_test, y_pred_dt, \"Decision Tree Confusion Matrix\", \"./images_Bow/confusion_matrix/dt_confusion_matrix.png\")\n",
    "plot_confusion_matrix(y_test, y_pred_stacking, \"Stacking Classifier Confusion Matrix\", \"./images_Bow/confusion_matrix/stacking_confusion_matrix.png\")\n",
    "\n",
    "# Stampa delle ROC-AUC Curve\n",
    "plot_roc_auc_curve(y_test, y_pred_gbm, \"Gradient Boosting Machine\", \"./images_Bow/roc_auc/gbm_roc_auc.png\")\n",
    "plot_roc_auc_curve(y_test, y_pred_ada, \"AdaBoost\", \"./images_Bow/roc_auc/ada_roc_auc.png\")\n",
    "plot_roc_auc_curve(y_test, y_pred_xgb, \"XGBoost\", \"./images_Bow/roc_auc/xgb_roc_auc.png\")\n",
    "plot_roc_auc_curve(y_test, y_pred_lgbm, \"LightGBM\", \"./images_Bow/roc_auc/lgbm_roc_auc.png\")\n",
    "plot_roc_auc_curve(y_test, y_pred_log_reg, \"Logistic Regression\", \"./images_Bow/roc_auc/logreg_roc_auc.png\")\n",
    "plot_roc_auc_curve(y_test, y_pred_rf, \"Random Forest\", \"./images_Bow/roc_auc/rf_roc_auc.png\")\n",
    "plot_roc_auc_curve(y_test, y_pred_knn, \"K-Nearest Neighbors\", \"./images_Bow/roc_auc/knn_roc_auc.png\")\n",
    "plot_roc_auc_curve(y_test, y_pred_dt, \"Decision Tree\", \"./images_Bow/roc_auc/dt_roc_auc.png\")\n",
    "plot_roc_auc_curve(y_test, y_pred_stacking, \"Stacking Classifier\", \"./images_Bow/roc_auc/stacking_roc_auc.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Raccoglie le statistiche per ogni modello, accuratazza, precisione, richiamo, f1, matrice di confusione e ROC-AUC\n",
    "models_stats = {\n",
    "    \"Gradient Boosting Machine\": evaluate_model(y_test, y_pred_gbm),\n",
    "    \"AdaBoost\": evaluate_model(y_test, y_pred_ada),\n",
    "    \"XGBoost\": evaluate_model(y_test, y_pred_xgb),\n",
    "    \"LightGBM\": evaluate_model(y_test, y_pred_lgbm),\n",
    "    \"Logistic Regression\": evaluate_model(y_test, y_pred_log_reg),\n",
    "    \"Random Forest\": evaluate_model(y_test, y_pred_rf),\n",
    "    \"K-Nearest Neighbors\": evaluate_model(y_test, y_pred_knn),\n",
    "    \"Decision Tree\": evaluate_model(y_test, y_pred_dt),\n",
    "    \"Stacking Classifier\": evaluate_model(y_test, y_pred_stacking)\n",
    "}\n",
    "\n",
    "# Creazione di un report di classificazione\n",
    "plot_classification_report(models_stats, \"./images_Bow/classification/classification_report\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Texttable object\n",
    "table = Texttable()\n",
    "\n",
    "# Add headers\n",
    "table.header([\"Model\", \"Accuracy\", \"Precision\", \"Recall\", \"F1 Score\", \"ROC AUC\"])\n",
    "\n",
    "# Add rows for each model's statistics\n",
    "for model, stats in models_stats.items():\n",
    "    table.add_row([model, stats['accuracy'], stats['precision'], stats['recall'], stats['f1'], stats['roc_auc']])\n",
    "\n",
    "# Draw the table\n",
    "print(table.draw())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save each model to a file\n",
    "joblib.dump(vectorizer, './models/BoW/vectorizer.pkl')\n",
    "joblib.dump(gbm, './models/BoW/gbm_model.pkl')\n",
    "joblib.dump(ada, './models/BoW/ada_model.pkl')\n",
    "joblib.dump(xgb, './models/BoW/xgb_model.pkl')\n",
    "joblib.dump(lgbm, './models/BoW/lgbm_model.pkl')\n",
    "joblib.dump(log_reg, './models/BoW/log_reg_model.pkl')\n",
    "joblib.dump(rf, './models/BoW/rf_model.pkl')\n",
    "joblib.dump(knn, './models/BoW/knn_model.pkl')\n",
    "joblib.dump(dt, './models/BoW/dt_model.pkl')\n",
    "joblib.dump(stacking, './models/BoW/stacking_model.pkl')\n",
    "\n",
    "print(\"Models have been saved successfully.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
